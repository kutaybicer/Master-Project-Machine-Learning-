import numpy as np 
import pandas as pd 
import os
import torch
import torchvision
from tensorflow import keras
import tensorflow as tf
from keras.layers import Dense,Dropout,Activation,Add,MaxPooling2D,Conv2D,Flatten,BatchNormalization
from keras.models import Sequential
from keras import layers
from keras.preprocessing.image import ImageDataGenerator
import numpy as np
import matplotlib.pyplot as plt
from keras.preprocessing import image
import numpy as np
import sklearn
from sklearn.metrics import roc_curve,auc
import sys
from collections import Counter

tf.test.gpu_device_name()
tf.test.is_gpu_available()

#model for data augmentation

train_datagen = ImageDataGenerator(rescale=1/255,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   vertical_flip =  True , 
                                   rotation_range=40,
                                   brightness_range = (0.5, 1.5),
                                   horizontal_flip = True)

#Saving synthetic images produced after data augmentation

# i = 0
# for batch in train_datagen.flow_from_directory('C:/Project/data_all_malignant',
#                                                  target_size = (50, 50),
#                                                  batch_size = 32,
#                                                  class_mode='sparse',
#                                                  shuffle=True,seed=1,
#                                                  save_to_dir='C:/Project/augmentation_generation',
#                                                  save_prefix='malignants',
#                                                  save_format='png'):
#     i += 1
#     if i > 1500: 
#         break 


#Loading test and train data

train_data = tf.keras.utils.image_dataset_from_directory(
    'C:/Project/data_augmentation/train',
    labels="inferred",
    label_mode='binary',
    class_names= ['benign','malignant'],
    validation_split=0.2,
    subset="training",
    batch_size=32,
    image_size=(50, 50),
    shuffle=True,
    seed=1
)


test_data = tf.keras.utils.image_dataset_from_directory(
    'C:/Project/data_augmentation/train',
    labels="inferred",
    label_mode='binary',
    class_names= ['benign','malignant'],
    validation_split=0.2,
    subset="validation",
    batch_size=32,
    image_size=(50, 50),
    shuffle=True,
    seed=1
)


#CNN model
model = Sequential([
Conv2D(32,kernel_size= 3,padding='valid',activation='relu',input_shape=(50,50,3)),
MaxPooling2D(pool_size=(2,2)),
Conv2D(64,kernel_size= 3,padding='valid',activation='relu'),
MaxPooling2D(pool_size=(2,2)),
Dropout(0.3),
Conv2D(128,kernel_size= 3,padding='valid',activation='relu'),
MaxPooling2D(pool_size=(2,2)),
Dropout(0.2),
    
Flatten(),
    
Dense(128,activation='relu'),
Dropout(0.1),
Dense(64,activation='relu'),
Dense(2,activation='sigmoid')])

model.compile(optimizer="adam", loss=keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])

#definition of early stop conditions
early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=5)

#Training
history=model.fit(train_data,
    validation_data = test_data , 
    callbacks=[early_stop],
    epochs = 20)
    
#test results
model.evaluate(test_data)

#Plottings
import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

accuracy = history.history['accuracy']
val_accuracy = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)


plt.plot(epochs, accuracy, color='b', label='Training Accuracy')
plt.plot(epochs, val_accuracy, color='r', label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()

plt.figure()

plt.plot(epochs, loss, color='g', label='Training Loss')
plt.plot(epochs, val_loss, color='y', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.show()
