import numpy as np 
import pandas as pd 
import os
import torch
import torchvision
from tensorflow import keras
import tensorflow as tf
from keras.layers import Dense,Dropout,Activation,Add,MaxPooling2D,Conv2D,Flatten,BatchNormalization
from keras.models import Sequential
from keras import layers
from keras.preprocessing.image import ImageDataGenerator
import numpy as np
import matplotlib.pyplot as plt
from keras.preprocessing import image
import numpy as np
import sklearn
from sklearn.metrics import roc_curve,auc
import sys
from torchvision import datasets
from torchvision import transforms
import torch.utils.data as data
import torch.nn as nn

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

batch_size = 32
num_classes = 2
learning_rate = 0.001

transform = transforms.Compose([
     transforms.ToTensor(),
     transforms.Resize((50,50))
])

dataset = datasets.ImageFolder(root='C:/Project/data333/dataset', transform=transform)

dataset_size = dataset.__len__()
train_count = int(dataset_size * 0.8)
val_count = dataset_size - train_count
train_dataset, valid_dataset = data.random_split(dataset, [train_count, val_count])

print('Train data set:', train_count)
print('Test data set:', val_count)

y_train_indices = train_dataset.indices

y_train = [dataset.targets[i] for i in y_train_indices]

class_sample_count = np.array(
    [len(np.where(y_train == t)[0]) for t in np.unique(y_train)])
    
weight = 1. / class_sample_count
samples_weight = np.array([weight[t] for t in y_train])
samples_weight = torch.from_numpy(samples_weight)

print("Class sample count: ", class_sample_count)
print("Weight: ", weight)

sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight))

train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, sampler=sampler)
valid_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32)

print('Train data set:', train_count)
print('Test data set:', val_count)
print('Length of dataloader:', len(train_dataloader))

class ConvNeuralNet(nn.Module):
 
    def __init__(self, num_classes):
        super(ConvNeuralNet, self).__init__()
        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)
        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)
        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)
        
        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)
        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)
        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)
        
        self.fc1 = nn.Linear(5184, 128)
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Linear(128, num_classes)
    
   
    def forward(self, x):
        out = self.conv_layer1(x)
        out = self.conv_layer2(out)
        out = self.max_pool1(out)
        
        out = self.conv_layer3(out)
        out = self.conv_layer4(out)
        out = self.max_pool2(out)
                
        out = out.reshape(out.size(0), -1)
        
        out = self.fc1(out)
        out = self.relu1(out)
        out = self.fc2(out)
        return out
        
model = ConvNeuralNet(num_classes)

criterion = nn.CrossEntropyLoss()


optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)  

total_step = len(train_dataloader)


loss_list=[]
for epoch in range(20):

    for i, (images, labels) in enumerate(train_dataloader):  

        images = images.to(device)
        labels = labels.to(device)
        

        outputs = model(images)
        loss = criterion(outputs, labels)
        
    
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
    
    loss_list.append(loss.item())

    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, 20, loss.item()))


train_accuracy =[]
with torch.no_grad():
    correct = 0
    total = 0
    for images, labels in train_dataloader:
        images = images.to(device)
        labels = labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        
        
        train_accuracy.append(100 * correct / total)
    
    print('Accuracy train total : {} %'.format(100 * correct / total))


 test_accuracy = []
with torch.no_grad():
    correct = 0
    total = 0
    for images, labels in valid_dataloader:
        images = images.to(device)
        labels = labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
        
       
        test_accuracy.append(100 * correct / total)
    
    print('Accuracy test  total : {} %'.format(100 * correct / total))
    


epochs = range(1, len(loss_list) + 1)

plt.plot(epochs, loss_list, color='r', label='Loss')
plt.title('Training Loss')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()

plt.show()
